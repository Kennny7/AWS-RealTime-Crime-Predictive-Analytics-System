# Crime Detection & Predictive Analytics System  
**Real-Time Severity Prediction Powered by Azure Cloud & Deep Learning**  
![Azure](https://img.shields.io/badge/Cloud-Microsoft%20Azure-0089D6?logo=microsoft-azure) 
![License](https://img.shields.io/badge/License-MIT-blue) 
![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)

![System Architecture](docs/architecture_diagram.png) *Conceptual Architecture Diagram*

## ğŸ“Œ Overview
A cloud-native system transforming crime analysis from reactive to proactive through:
- **Real-time crime severity prediction** using Deep Neural Networks
- **Stream processing** of incident reports via Kafka/Event Hubs
- **Interactive dashboards** with live heatmaps and trend analysis
- **Azure-powered** big data processing (Databricks, Data Lake, AML)
- **Fully automated pipeline** from data ingestion to police alerts

## ğŸŒ³ Project Structure
```bash
crime-prediction-system/
â”œâ”€â”€ data/                   # Raw and processed datasets
â”‚   â”œâ”€â”€ raw/                # Initial crime records from Azure Blob
â”‚   â”‚   â””â”€â”€ crime_records.csv
â”‚   â””â”€â”€ processed/          # Cleaned data in Parquet format
â”‚       â””â”€â”€ crime_data.parquet
â”‚
â”œâ”€â”€ preprocessing/          # Data transformation scripts
â”‚   â”œâ”€â”€ spark_jobs/         # PySpark data pipelines
â”‚   â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â””â”€â”€ config/             # Databricks configurations
â”‚       â””â”€â”€ databricks_config.yaml
â”‚
â”œâ”€â”€ model/                  # Machine learning components
â”‚   â”œâ”€â”€ training/           # ANN model development
â”‚   â”‚   â”œâ”€â”€ ann_model.ipynb
â”‚   â”‚   â””â”€â”€ hyperparameters.json
â”‚   â”œâ”€â”€ evaluation/         # Performance metrics
â”‚   â”‚   â”œâ”€â”€ metrics_calculator.py
â”‚   â”‚   â””â”€â”€ confusion_matrix.png
â”‚   â””â”€â”€ registry/           # Azure ML integration
â”‚       â””â”€â”€ model_loader.py
â”‚
â”œâ”€â”€ real_time/              # Streaming infrastructure
â”‚   â”œâ”€â”€ api/                # FastAPI endpoints
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ crime_schemas.py
â”‚   â”œâ”€â”€ streaming/          # Kafka/Spark processors
â”‚   â”‚   â”œâ”€â”€ kafka_consumer.py
â”‚   â”‚   â””â”€â”€ event_processor.py
â”‚   â””â”€â”€ schemas/            # Avro data contracts
â”‚       â””â”€â”€ crime_report.avsc
â”‚
â”œâ”€â”€ storage/                # Data persistence layer
â”‚   â”œâ”€â”€ data_lake_connector.py
â”‚   â””â”€â”€ historical_db/      # Processed crime archive
â”‚
â”œâ”€â”€ dashboard/              # Visualization interfaces
â”‚   â”œâ”€â”€ streamlit/          # Real-time dashboard
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ map_visualizer.py
â”‚   â”œâ”€â”€ powerbi/            # Analytical reports
â”‚   â”‚   â””â”€â”€ crime_heatmap.pbix
â”‚   â””â”€â”€ assets/             # UI resources
â”‚       â”œâ”€â”€ styles.css
â”‚       â””â”€â”€ crime_icons/
â”‚
â”œâ”€â”€ deployment/             # Cloud infrastructure
â”‚   â”œâ”€â”€ docker/             # Container configurations
â”‚   â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”‚   â””â”€â”€ Dockerfile.streaming
â”‚   â”œâ”€â”€ scripts/            # Deployment automation
â”‚   â”‚   â””â”€â”€ azure_deploy.sh
â”‚   â””â”€â”€ infra-as-code/      # ARM templates
â”‚       â””â”€â”€ main_template.json
â”‚
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ architecture_diagram.pdf
â”‚   â”œâ”€â”€ api_documentation.md
â”‚   â””â”€â”€ user_guide.md
â”‚
â”œâ”€â”€ tests/                  # Quality assurance
â”‚   â”œâ”€â”€ unit/               # Component tests
â”‚   â”‚   â”œâ”€â”€ test_data_processing.py
â”‚   â”‚   â””â”€â”€ test_model.py
â”‚   â””â”€â”€ integration/        # System tests
â”‚       â””â”€â”€ test_api_endpoints.py
â”‚
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ config.yaml             # Central configuration
â””â”€â”€ .gitignore              # Version control rules
```

## ğŸš€ Key Features
- **Predictive Crime Modeling**: MLP-based ANN with 92% prediction accuracy
- **Real-Time Processing**: <5s latency from report ingestion to severity classification
- **Unified Data Platform**: Handles both batch (historical) and streaming (live) data
- **Police Dashboard**: Real-time alerts with location-based severity visualization
- **Scalable Infrastructure**: Auto-scaling Azure App Services + Spark clusters

## ğŸ— System Architecture
```ascii
Data Flow:
[Public Sources] â†’ [Azure Blob Storage]
       â†“
[Databricks Preprocessing] â†’ [Parquet Files]
       â†“
[AML Model Training] â†’ [Model Registry]
       â†“
[FastAPI] â†’ [Kafka/Event Hubs] â†’ [Spark Streaming]
       â†“
[Severity Predictions] â†’ [Data Lake] 
       â†“
[Streamlit/Power BI Dashboards]
```

**Core Components**  
| Directory | Purpose | Key Technologies |
|-----------|---------|------------------|
| `data/` | Raw/processed crime datasets | Azure Blob, Parquet |
| `preprocessing/` | Data cleaning/transformation | PySpark, Azure Databricks |
| `model/` | ANN model development | TensorFlow, Azure ML |
| `real_time/` | Streaming pipeline | FastAPI, Kafka, Spark Streaming |
| `dashboard/` | Visualization interfaces | Streamlit, Power BI |
| `deployment/` | Cloud infrastructure | ARM Templates, Docker |

## âš™ï¸ Installation & Setup

### Prerequisites
- Azure Account with Owner permissions
- Python 3.10+ 
- Azure CLI 2.45.0+
- Kafka 3.4.0+ (or Azure Event Hubs)

### Local Development
```bash
git clone https://github.com/Kennny7/RealTime-Crime-Predictive-Analytics-System.git
cd crime-prediction-system

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac)
# .venv\Scripts\activate  # Windows

pip install -r requirements.txt

# Configure environment
cp config.example.yaml config.yaml
```

### Cloud Deployment
```bash
# Deploy Azure resources
az deployment sub create \
  --name CrimePredictionDeployment \
  --location eastus \
  --template-file deployment/infra-as-code/main_template.json

# Build & push Docker images
az acr build --registry <your-registry> \
  --image crime-api:latest \
  --file deployment/docker/Dockerfile.api .
```

## ğŸ”§ Configuration
Update `config.yaml` with your Azure credentials:
```yaml
azure:
  storage_account: "crimesaprod"
  blob_container: "raw-reports"
  databricks_workspace: "/subscriptions/.../crime-db"

kafka:
  bootstrap_servers: "crime-kafka.servicebus.windows.net:9093"
  topic_in: "raw-reports"
  topic_out: "severity-predictions"

model:
  registry_name: "crime_severity_ann"
  version: "1.2.0"
```

## ğŸ›  Usage

### Data Ingestion
```python
from real_time.api.main import CrimeReport

report = CrimeReport(
    type="burglary",
    coordinates={"lat": 40.7128, "lon": -74.0060},
    timestamp="2024-02-15T14:30:00Z"
)
response = post("https://api.crime-system.com/v1/report", json=report.dict())
```

### Model Training
```bash
# Submit Databricks job
databricks jobs submit \
  --python-task model/training/ann_model.ipynb \
  --cluster-id 1234-567890-reef123
```

### Real-Time API
```bash
uvicorn real_time.api.main:app --host 0.0.0.0 --port 8000

# Test endpoint
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"type": "assault", "coordinates": {"lat": 34.0522, "lon": -118.2437}}'
```

### Dashboards
```bash
# Streamlit
streamlit run dashboard/streamlit/app.py

# Power BI
powerbi://dataset=crime_heatmap.pbix
```

## ğŸ¤ Contributing
1. Fork the repository
2. Create feature branch (`git checkout -b feature/improved-model`)
3. Commit changes (`git commit -m 'Add XGBoost benchmark'`)
4. Push to branch (`git push origin feature/improved-model`)
5. Open Pull Request

## ğŸ“„ License
Distributed under MIT License. See `LICENSE`(LICENSE) for details.

## ğŸ“§ Contact
**Project Maintainer** - Khushal Pareta - https://Kennny7.github.io  
**Technical Lead** - Khushal Pareta - https://Kennny7.github.io

---

*This project was developed in collaboration with law enforcement agencies to enhance public safety through predictive analytics. For production deployment guidance, contact our Azure Solutions Team.*

